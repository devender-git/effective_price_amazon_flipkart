{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49217e3d-a912-4a11-b252-b3e97e1a9b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b470da9-811a-4040-b33d-d3558722a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020c8e8a-aed5-42ec-bda0-2820df6ba028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample store data with addresses and coordinates\n",
    "store_data = [\n",
    "    {\"name\": \"Store A\", \"address\": \"Kanagal S.O\", \"lat\": 12.5615, \"lon\": 75.9921 },\n",
    "    {\"name\": \"Store B\", \"address\": \"Kattemalalavadi S.O\", \"lat\": 12.3179, \"lon\": 76.3363},\n",
    "    # Add more store data here...\n",
    "]\n",
    "\n",
    "# Create a map centered at an initial location\n",
    "initial_location = [store_data[0][\"lat\"], store_data[0][\"lon\"]]\n",
    "m = folium.Map(location=initial_location, zoom_start=10)\n",
    "\n",
    "# Add markers for each store\n",
    "for store in store_data:\n",
    "    folium.Marker(\n",
    "        location=[store[\"lat\"], store[\"lon\"]],\n",
    "        popup=store[\"name\"],\n",
    "        tooltip=store[\"address\"]\n",
    "    ).add_to(m)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "m.save(\"store_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "705672d8-2d3d-4c49-9f27-7cfd5ef24c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbc0965-1601-4f0d-8cf2-f3236716026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"}\n",
    "    ],\n",
    "temperature=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "696bdfdc-8c2d-4925-9e25-da9d70c3569d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8AAnCcyDSkRCOVAuujUy4uQku75jN at 0x1384c5c6b60> JSON: {\n",
       "  \"id\": \"chatcmpl-8AAnCcyDSkRCOVAuujUy4uQku75jN\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1697435458,\n",
       "  \"model\": \"gpt-4-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Orange who?\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 35,\n",
       "    \"completion_tokens\": 3,\n",
       "    \"total_tokens\": 38\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = openai.ChatCompletion.create(model=\"gpt-4\", messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"}\n",
    "    ],\n",
    "temperature=0)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f4a56a-418d-48ca-ada7-4bd2b94f5efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8AAjdvtAFYnFyRtzIyUzLjEfyT0HV at 0x1384c568180> JSON: {\n",
       "  \"id\": \"chatcmpl-8AAjdvtAFYnFyRtzIyUzLjEfyT0HV\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1697435237,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Orange who?\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 35,\n",
       "    \"completion_tokens\": 3,\n",
       "    \"total_tokens\": 38\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4509c8e-d2c7-4270-bd3b-1233af2c0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import OpenAI\n",
    "import sys\n",
    "import os\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69283eb6-0ccf-44e6-92b5-9a27d2781bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "context ='''SBI\n",
    "Xiaomi 13 Pro (12/256)\n",
    "12+256\n",
    "74999\n",
    "5000\n",
    "69999\n",
    "AMZ\n",
    "ICICI/Axis/Citi/HDFC\n",
    "Redmi Note 12 Pro+ 5G (8/256)\n",
    "8+256\n",
    "29999\n",
    "2000\n",
    "3000\n",
    "24999\n",
    "FK\n",
    "ICICI/Axis/Kotak/HDFC\n",
    "Redmi Note 12 Pro 5G (12/256)\n",
    "12+256\n",
    "28999\n",
    "3000\n",
    "3000\n",
    "22999\n",
    "FK\n",
    "ICICI/Axis/Kotak/HDFC\n",
    "Redmi Note 12 Pro 5G (6/128)\n",
    "6+128\n",
    "23999\n",
    "3000\n",
    "3000\n",
    "17999\n",
    "FK\n",
    "ICICI/Axis/Kotak/HDFC\n",
    "Redmi Note 12 Pro 5G (8/256)\n",
    "8+256\n",
    "26999\n",
    "4000\n",
    "3000\n",
    "19999\n",
    "FK\n",
    "SBI - AMZ; ICICI/Axis/Kotak - FK\n",
    "Redmi Note 12 5G (4/128)\n",
    "4+128\n",
    "16999\n",
    "1000\n",
    "2000\n",
    "13999\n",
    "AMZ,FK'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53f2a1c9-7028-46f5-8d1f-c5097a73865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"discount on phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1404aa52-8b50-49ec-92d6-df86b9a8a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "  The following is a friendly conversation between a human and an AI. \n",
    "  The AI is talkative and provides lots of specific details asked in question from its context.\n",
    "  If the AI does not know the answer to a question, it truthfully says it \n",
    "  does not know.\n",
    "  {context}\n",
    "  Instruction: Based on the above documents, provide a detailed answer for, {question} AMZ refers to Amazon & FK refers to Flipkart which are channel/exclusive/ecommerce platform. Answer \"I have information on discounts and prices for the latest Xiaomi products, which I can provide. As for your question, I'm sorry, but I don't know the answer to that.\" if not present in the document. \n",
    "  Solution:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5977baf0-52fd-4a1d-bafb-7297331efced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devenderjhinkwan\\ML_PATH\\effective_price_amazon_flipkart\\myenv\\lib\\site-packages\\langchain\\llms\\openai.py:202: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\devenderjhinkwan\\ML_PATH\\effective_price_amazon_flipkart\\myenv\\lib\\site-packages\\langchain\\llms\\openai.py:790: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name='gpt-4', temperature=0.0, max_tokens=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1435c8-23ff-4de8-bb8f-111b3e3cc209",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-ada-002')\n",
    "vectordb = FAISS.load_local(cfg.DB_FAISS_PATH, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "820a79d6-2838-48c4-847d-c1a0942ce599",
   "metadata": {},
   "outputs": [],
   "source": [
    " def completion_with_backoff():\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm, \n",
    "        retriever=vectordb.as_retriever(search_kwargs={'k': cfg.VECTOR_COUNT}), \n",
    "        chain_type=\"stuff\",\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\":PROMPT})\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "851b1b54-e19a-43ed-b363-053496b16fed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectordb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output\u001b[38;5;241m=\u001b[39m\u001b[43mcompletion_with_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m, in \u001b[0;36mcompletion_with_backoff\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompletion_with_backoff\u001b[39m():\n\u001b[0;32m      2\u001b[0m    qa \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[0;32m      3\u001b[0m        llm\u001b[38;5;241m=\u001b[39mllm, \n\u001b[1;32m----> 4\u001b[0m        retriever\u001b[38;5;241m=\u001b[39m\u001b[43mvectordb\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: cfg\u001b[38;5;241m.\u001b[39mVECTOR_COUNT}), \n\u001b[0;32m      5\u001b[0m        chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m        return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m        chain_type_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m:PROMPT})\n\u001b[0;32m      8\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m qa\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectordb' is not defined"
     ]
    }
   ],
   "source": [
    "output=completion_with_backoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633314e3-939a-4090-8bb1-74630f4168fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
